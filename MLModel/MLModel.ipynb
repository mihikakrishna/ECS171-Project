{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "from skimage import io\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second using video.get(cv2.CAP_PROP_FPS) : 1\n"
     ]
    }
   ],
   "source": [
    "# Starts capturing video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Captured Frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    keypress = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(image, aWeight):\n",
    "    # initialize the background\n",
    "    bg = None\n",
    "\n",
    "    # if the background is None, initialize it\n",
    "    if bg is None:\n",
    "        bg = image.copy().astype(\"float\")\n",
    "        return None\n",
    "\n",
    "    # compute weighted average, accumulate it and update the background\n",
    "    cv2.accumulateWeighted(image, bg, aWeight)\n",
    "\n",
    "    # compute absolute difference between the background and current frame\n",
    "    diff = cv2.absdiff(bg.astype(\"uint8\"), image)\n",
    "\n",
    "    # threshold the diff image so that we get the foreground\n",
    "    thresholded = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # get the contours in the thresholded image\n",
    "    cnts, _ = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # return None, if no contours detected\n",
    "    if len(cnts) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        # based on contour area, get the maximum contour which is the hand\n",
    "        segmented = max(cnts, key=cv2.contourArea)\n",
    "        return (thresholded, segmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 98, 118, 32)       320       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 98, 118, 32)      128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 49, 59, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 49, 59, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 47, 57, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 47, 57, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 23, 28, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 23, 28, 64)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 41216)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               5275776   \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,295,750\n",
      "Trainable params: 5,295,558\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers import Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "# first conv layer\n",
    "# input shape = (img_rows, img_cols, 1)\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(100,120, 1))) \n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# second conv layer\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# flatten and put a fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu')) # fully connected\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# softmax layer\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "optimiser = Adam() \n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/ok',\n",
       " 'data/thumbsup',\n",
       " 'data/blank',\n",
       " 'data/thumbsdown',\n",
       " 'data/fist',\n",
       " 'data/five']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Dataset\n",
    "\n",
    "DATASET_PATH = 'data'\n",
    "\n",
    "dataset_path = os.path.join(DATASET_PATH, '*')\n",
    "import glob\n",
    "dataset_path = glob.glob(dataset_path)\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17299ab00>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "image = cv2.imread('data/five/hand1(1015).jpg')\n",
    "image = cv2.resize(image,(100, 120))\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600\n",
      "9600\n"
     ]
    }
   ],
   "source": [
    "loaded_images = []\n",
    "\n",
    "list_of_gestures = ['blank', 'ok', 'thumbsup', 'thumbsdown', 'fist', 'five']\n",
    "\n",
    "for path in range(0, len(dataset_path)):\n",
    "    dataset_path = \"data/\" + str(list_of_gestures[path])\n",
    "    gesture_path = os.path.join(dataset_path, '*')\n",
    "    import glob\n",
    "    gest_path = glob.glob(gesture_path)\n",
    "    k = 0\n",
    "    for i in range(0, len(gest_path)):\n",
    "        if k < 1600:\n",
    "            image = cv2.imread(gest_path[i])\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            gray_image = cv2.resize(gray_image,(100, 120))\n",
    "            loaded_images.append(gray_image)\n",
    "        k=k+1\n",
    "print(len(loaded_images))\n",
    "\n",
    "outputVectors = []\n",
    "for i in range(1, 1601):\n",
    "    outputVectors.append([1, 0, 0, 0, 0, 0])\n",
    "\n",
    "for i in range(1, 1601):\n",
    "    outputVectors.append([0, 1, 0, 0, 0, 0])\n",
    "\n",
    "for i in range(1, 1601):\n",
    "    outputVectors.append([0, 0, 1, 0, 0, 0])\n",
    "    \n",
    "for i in range(1, 1601):\n",
    "    outputVectors.append([0, 0, 0, 1, 0, 0])\n",
    "    \n",
    "for i in range(1, 1601):\n",
    "    outputVectors.append([0, 0, 0, 0, 1, 0])\n",
    "\n",
    "for i in range(1, 1601):\n",
    "    outputVectors.append([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "print(len(outputVectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9600, 120, 100)\n",
      "(9600, 6)\n"
     ]
    }
   ],
   "source": [
    "X = np.asarray(loaded_images)\n",
    "y = np.asarray(outputVectors)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7680, 100, 120, 1)\n",
      "(1920, 100, 120, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "X_train = X_train.reshape(X_train.shape[0], 100, 120, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 100, 120, 1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 64s 1s/step - loss: 2.2889 - categorical_accuracy: 0.7056 - val_loss: 0.3175 - val_categorical_accuracy: 0.8776\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.3473 - categorical_accuracy: 0.8406 - val_loss: 0.1028 - val_categorical_accuracy: 0.9625\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 78s 1s/step - loss: 0.2859 - categorical_accuracy: 0.8602 - val_loss: 0.1056 - val_categorical_accuracy: 0.9646\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 61s 1s/step - loss: 0.2272 - categorical_accuracy: 0.8854 - val_loss: 0.0990 - val_categorical_accuracy: 0.9490\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 63s 1s/step - loss: 0.1978 - categorical_accuracy: 0.9010 - val_loss: 0.0419 - val_categorical_accuracy: 0.9870\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 62s 1s/step - loss: 0.1866 - categorical_accuracy: 0.9079 - val_loss: 0.0360 - val_categorical_accuracy: 0.9880\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.1467 - categorical_accuracy: 0.9296 - val_loss: 0.0257 - val_categorical_accuracy: 0.9917\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 59s 984ms/step - loss: 0.1232 - categorical_accuracy: 0.9410 - val_loss: 0.0244 - val_categorical_accuracy: 0.9958\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 62s 1s/step - loss: 0.1203 - categorical_accuracy: 0.9402 - val_loss: 0.0135 - val_categorical_accuracy: 0.9984\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.1075 - categorical_accuracy: 0.9469 - val_loss: 0.0072 - val_categorical_accuracy: 0.9979\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "model.save(\"hand_gesture_recognition.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 6s 100ms/step - loss: 0.0072 - categorical_accuracy: 0.9979\n",
      "Accuracy: 0.9979166388511658\n"
     ]
    }
   ],
   "source": [
    "[loss, acc] = model.evaluate(X_test,y_test,verbose=1)\n",
    "print(\"Accuracy: \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] please wait! calibrating...\n"
     ]
    }
   ],
   "source": [
    "# load Model Weights\n",
    "\n",
    "def _load_weights():\n",
    "    try:\n",
    "        model = load_model(\"hand_gesture_recog_model.h5\")\n",
    "        print(model.summary())\n",
    "        # print(model.get_weights())\n",
    "        # print(model.optimizer)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "    \n",
    "def getPredictedClass(model):\n",
    "\n",
    "    image = cv2.imread('Temp.png')\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = cv2.resize(gray_image, (100, 120))\n",
    "\n",
    "    gray_image = gray_image.reshape(1, 100, 120, 1)\n",
    "\n",
    "    prediction = model.predict_on_batch(gray_image)\n",
    "    print(prediction)\n",
    "\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    if predicted_class == 0:\n",
    "        return \"Blank\"\n",
    "    elif predicted_class == 1:\n",
    "        return \"OK\"\n",
    "    elif predicted_class == 2:\n",
    "        return \"Thumbs Up\"\n",
    "    elif predicted_class == 3:\n",
    "        return \"Thumbs Down\"\n",
    "    elif predicted_class == 4:\n",
    "        return \"Punch\"\n",
    "    elif predicted_class == 5:\n",
    "        return \"High Five\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # initialize accumulated weight\n",
    "    accumWeight = 0.5\n",
    "\n",
    "    # get the reference to the webcam\n",
    "    camera = cv2.VideoCapture(0)\n",
    "\n",
    "    fps = int(camera.get(cv2.CAP_PROP_FPS))\n",
    "    # region of interest (ROI) coordinates\n",
    "    top, right, bottom, left = 10, 350, 225, 590\n",
    "    # initialize num of frames\n",
    "    num_frames = 0\n",
    "    # calibration indicator\n",
    "    calibrated = False\n",
    "    model = _load_weights()\n",
    "    k = 0\n",
    "    # keep looping, until interrupted\n",
    "    while (True):\n",
    "        # get the current frame\n",
    "        (grabbed, frame) = camera.read()\n",
    "\n",
    "        # resize the frame\n",
    "        frame = cv2.resize(frame, (700,700))\n",
    "        # flip the frame so that it is not the mirror view\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # clone the frame\n",
    "        clone = frame.copy()\n",
    "\n",
    "        # get the height and width of the frame\n",
    "        (height, width) = frame.shape[:2]\n",
    "\n",
    "        # get the ROI\n",
    "        roi = frame[top:bottom, right:left]\n",
    "\n",
    "        # convert the roi to grayscale and blur it\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "        # to get the background, keep looking till a threshold is reached\n",
    "        # so that our weighted average model gets calibrated\n",
    "        if num_frames < 30:\n",
    "            True\n",
    "            # run_avg(gray, accumWeight)\n",
    "            if num_frames == 1:\n",
    "                print(\"[STATUS] please wait! calibrating...\")\n",
    "            elif num_frames == 29:\n",
    "                print(\"[STATUS] calibration successfull...\")\n",
    "        else:\n",
    "            # segment the hand region\n",
    "            hand = segment(gray, accumWeight)\n",
    "\n",
    "            # check whether hand region is segmented\n",
    "            if hand is not None:\n",
    "                # if yes, unpack the thresholded image and\n",
    "                # segmented region\n",
    "                (thresholded, segmented) = hand\n",
    "\n",
    "                # draw the segmented region and display the frame\n",
    "                cv2.drawContours(clone, [segmented + (right, top)], -1, (0, 0, 255))\n",
    "\n",
    "                # count the number of fingers\n",
    "                # fingers = count(thresholded, segmented)\n",
    "                if k % (fps / 6) == 0:\n",
    "                    cv2.imwrite('Temp.png', thresholded)\n",
    "                    predictedClass = getPredictedClass(model)\n",
    "                    cv2.putText(clone, str(predictedClass), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "                # show the thresholded image\n",
    "                cv2.imshow(\"Thesholded\", thresholded)\n",
    "        k = k + 1\n",
    "        # draw the segmented hand\n",
    "        cv2.rectangle(clone, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "        # increment the number of frames\n",
    "        num_frames += 1\n",
    "\n",
    "        # display the frame with segmented hand\n",
    "        cv2.imshow(\"Video Feed\", clone)\n",
    "\n",
    "        # observe the keypress by the user\n",
    "        keypress = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if the user pressed \"q\", then stop looping\n",
    "        if keypress == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # free up memory\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
